{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analyst/Scientist Intern Assessment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kindly write your full legal name, surname, working phone number and email address into this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the KPI.com Data Analyst/Scientist Intern assessment. This notebook is designed to evaluate your proficiency and skills relevant to the role. Below are the key expectations for this assessment:\n",
    "\n",
    "## Candidate Expectations:\n",
    "\n",
    "- **Proficiency in Key Libraries**: You are expected to be proficient in Python libraries such as `pandas`, `numpy`, `scikit-learn`  and `matplotlib`.\n",
    "- **Code Quality**: Your code should be neat and concise. Strive for clarity and efficiency in your solutions.\n",
    "- **Use of Functions**: Demonstrate your ability to modularize code by using functions where necessary.\n",
    "\n",
    "## Application of Skills:\n",
    "\n",
    "Your data analysis skills will be pivotal for several cutting-edge projects at KPI.com. These include:\n",
    "\n",
    "- **Building Language-Based Models**: Utilizing models like GPT-3.5/4, Langchain, and LLaMA for various applications.\n",
    "- **Development of AI-Powered Dashboards**: Creating interactive and informative dashboards to visualize and interpret data.\n",
    "- **Speech Assistants**: Contributing to the development of AI-driven speech assistants.\n",
    "\n",
    "This assessment is an opportunity for you to showcase your abilities in a practical context, relevant to the dynamic and innovative projects at KPI.com.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Basic data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "This task is designed to assess your ability to import, manipulate, and analyze a dataset that contains both textual and quantitative data. You will be working with the 'Wine Reviews' dataset, which provides a more realistic and challenging scenario than basic datasets like Iris.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "1. **Data Importation**:\n",
    "    - Import the Wine Reviews dataset. This dataset can be found on Kaggle and can be imported using Pandas:\n",
    "      ```python\n",
    "      import pandas as pd\n",
    "      wine_reviews = pd.read_csv('path_to_dataset/winemag-data-130k-v2.csv')\n",
    "      ```\n",
    "      the dataset should be around 52.91 mb in case you find similar datasets \n",
    "    - Note 1: You may need to download the dataset from [Kaggle](https://www.kaggle.com/zynicide/wine-reviews) and adjust the path accordingly.\n",
    "    - Note 2: For our convinience create adjustable path as a separate variable for the file, such that we can simply replace it while checking\n",
    "2. **Basic Data Manipulation**:\n",
    "    - **Explore the Data**: Display the first 5 rows of the dataset to understand its structure.\n",
    "    - **Data Cleaning**: Check for and handle any missing values in the dataset.\n",
    "    - **Data Transformation**:\n",
    "        - Select a subset of columns that includes both text (like review descriptions) and quantitative data (like points or price).\n",
    "        - Perform a basic transformation, such as normalizing numerical columns of your choice, and explain why this transformation is helpful.\n",
    "\n",
    "3. **Brief Analysis**:\n",
    "    - Provide a short analysis of the dataset based on the manipulations performed. Discuss any interesting patterns or insights you find, particularly focusing on how the textual and quantitative data relate to each other.\n",
    "\n",
    "## Deliverable:\n",
    "- Lines of codes in a Jupyter notebook containing all executed output for the analyses, along with comments and interpretations of the results.\n",
    "## Evaluation Criteria:\n",
    "- Correctness of code.\n",
    "- Ability to perform basic data manipulation tasks, especially handling both textual and numerical data.\n",
    "- Clarity and organization of code and comments.\n",
    "\n",
    "The 'Wine Reviews' dataset offers a rich context for data manipulation and analysis, making it an excellent choice for showcasing your ability to handle diverse data types. This task will demonstrate your foundational skills in data handling, crucial for the advanced data analysis and model building tasks in your role.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lines down and write your codes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Statistical Analysis with the Wine Reviews Dataset\n",
    "\n",
    "## Objective:\n",
    "This task aims to evaluate your statistical analysis skills. Using the 'Wine Reviews' dataset, you will perform various statistical analyses to derive insights and understand patterns in the data.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "1. **Statistical Summaries**:\n",
    "    - Compute summary statistics (mean, median, standard deviation, etc.) for the numerical columns in the dataset (like points or price).\n",
    "    - Create a brief summary explaining these statistics in the context of the dataset.\n",
    "\n",
    "2. **Correlation Analysis**:\n",
    "    - Analyze the correlation between different numerical variables (e.g., price and points).\n",
    "    - Visualize these correlations using a heatmap or scatter plots.\n",
    "    - Provide insights on any strong correlations or lack thereof and what they might imply about the dataset.\n",
    "    - How would you evaluate the impact of the variables to the price of the product?\n",
    "\n",
    "3. **Optional Advanced Analysis: Hypothesis Testing**:\n",
    "    - Formulate a hypothesis related to the dataset. For example, \"Wines from a particular country have higher average ratings than the global average.\"\n",
    "    - Perform appropriate statistical tests to validate or refute your hypothesis.\n",
    "    - Discuss the results and their implications in the context of wine reviews.\n",
    "    - If you are comfortable, perform a more advanced statistical analysis of your choice. This could involve regression models, clustering, etc.\n",
    "\n",
    "## Deliverable:\n",
    "- Lines of codes in a Jupyter notebook containing all executed output for the analyses, along with comments and interpretations of the results.\n",
    "\n",
    "## Evaluation Criteria:\n",
    "- Correct application of statistical methods.\n",
    "- Depth and relevance of insights derived from the analysis.\n",
    "- Clarity and organization of code, comments, and interpretations.\n",
    "\n",
    "In this task, you will apply your statistical knowledge to real-world data, demonstrating your ability to extract meaningful insights from complex datasets. This skill is crucial for the advanced data analysis and predictive modeling tasks in your role.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lines down and write your codes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Statistical Intuition Questions\n",
    "\n",
    "## Objective:\n",
    "This task is designed to assess your intuitive understanding of key statistical concepts fundamental to data analysis.\n",
    "\n",
    "## Questions:\n",
    "\n",
    "1. **Standardization of Variables**:\n",
    "   - *Why is it important to standardize variables before performing certain statistical analyses or using specific machine learning algorithms?*\n",
    "\n",
    "2. **Encoding of Categorical Variables in Regression**:\n",
    "   - *In regression models, why are categorical variables often encoded as 0 and 1 (binary encoding), instead of using numerical labels like 1, 2, 3, etc.?*\n",
    "\n",
    "3. **Reliance on Statistical Tables for t-test or f-test**:\n",
    "   - *Why do we rely on tables (or software functions) to determine critical values or p-values for tests like the t-test or f-test?*\n",
    "\n",
    "4. **Importance of Data Visualization**:\n",
    "   - *Why is data visualization an important step in data analysis?*\n",
    "\n",
    "5. **Handling Missing Data**:\n",
    "   - *What are some common strategies for handling missing data in a dataset, and why is it important to address missing data appropriately?*\n",
    "\n",
    "6. **Impact of Outliers**:\n",
    "   - *How can outliers impact the results of statistical analyses, and what are some ways to handle outliers in your data?*\n",
    "\n",
    "7. **Choice of Statistical Tests**:\n",
    "   - *How do you decide which statistical test (e.g., t-test, ANOVA, chi-square test) to use in a given scenario?*\n",
    "\n",
    "## Deliverable:\n",
    "- Provide written responses to each question, demonstrating your understanding of these fundamental statistical concepts. Two to five sentences each would be enough, and feel free to use technical English when needed.\n",
    "\n",
    "## Evaluation Criteria:\n",
    "- The accuracy and clarity of your explanations.\n",
    "- Your ability to demonstrate an understanding of basic statistical principles and their practical applications.\n",
    "\n",
    "This task aims to gauge your foundational knowledge in statistics, which is crucial for making informed decisions in data analysis and ensuring the validity of your results. Your responses will help us understand your capability to apply these concepts in real-world data scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lines down and write your codes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Text Analysis\n",
    "\n",
    "## Objective:\n",
    "This task aims to evaluate your skills in text analysis, which are crucial for working with AI and machine learning tools like PyTorch, TensorFlow, Hugging Face, Langchain, and others. You will be working with a text dataset to perform basic processing and analysis.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "1. **Dataset Selection**:\n",
    "    - Choose a text dataset that is suitable for analysis. In this task, we decided to give you flexibility to choose the text data on your own. Some popular options include datasets from [Hugging Face Datasets](https://huggingface.co/datasets) or [Kaggle](https://www.kaggle.com/datasets).\n",
    "\n",
    "2. **Basic Text Processing**:\n",
    "    - Once you decide on the dataset, import it in some way that is reproducible from our side as well\n",
    "    - Perform basic text processing tasks such as tokenization, stop word removal, and stemming or lemmatization\n",
    "    - Feel free to create functions, and briefly document them (no need to create separate file, use docstrings instead)\n",
    "    - Display the processed text to show the results of your text processing steps.\n",
    "\n",
    "3. **Text Analysis**:\n",
    "    - Compute the frequency distribution of words or phrases in the dataset.\n",
    "    - Identify and visualize the most common words or phrases.\n",
    "    - Perform sentiment analysis on a subset of reviews, if the dataset contains review or opinion texts.\n",
    "\n",
    "4. **Insight Generation**:\n",
    "    - In two or three sentences, explain why did you find this particular dataset interesting\n",
    "    - Based on your text analysis, generate insights about the dataset. Discuss any interesting patterns or findings you observe.\n",
    "\n",
    "## Deliverable:\n",
    "- A chapter in Jupyter notebook containing all executed code for the text processing and analysis tasks, along with comments and interpretations of the results.\n",
    "\n",
    "## Evaluation Criteria:\n",
    "- Correct implementation of text processing and analysis techniques.\n",
    "- Depth and relevance of insights derived from the text analysis.\n",
    "- Clarity and organization of code, comments, and interpretations.\n",
    "\n",
    "Through this task, you will demonstrate your ability to handle and analyze text data, which is a foundational skill for working with advanced AI and machine learning technologies. Your proficiency in extracting meaningful information from text will be crucial for the innovative projects at KPI.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lines down and write your codes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Assessment Notes\n",
    "\n",
    "Thank you for participating in this assessment. As you conclude, please keep in mind the following key points:\n",
    "\n",
    "## Clarity and Readability of Code:\n",
    "- Your code should be clear and easy to understand. This includes proper indentation, meaningful variable names, and thoughtful organization of your code.\n",
    "- Clear and readable code is crucial for effective teamwork and maintainability of projects.\n",
    "\n",
    "## Time Allocation:\n",
    "- You are expected to spend approximately 3-4 hours on this assessment. This timeframe is designed to balance thoroughness with efficiency, reflecting real-world work scenarios.\n",
    "\n",
    "## Use of Markdown for Written Answers:\n",
    "- Please provide your written answers in Markdown format. This helps in maintaining a consistent and readable format for your responses.\n",
    "\n",
    "## Commentary and Documentation:\n",
    "- Feel free to add comments throughout your code. This practice is highly encouraged as it provides insight into your thought process and makes it easier for us to understand your approach.\n",
    "- Effective commenting and documentation are key skills in a collaborative and professional environment.\n",
    "\n",
    "## Focus on Statistical Understanding:\n",
    "- Although this is a position for a Data Analyst/Scientist Intern, a strong foundation in statistics is essential. You will be expected to learn and apply machine learning concepts during your internship.\n",
    "- We are looking for candidates who demonstrate a rigorous understanding of statistics, as this is fundamental to success in machine learning and advanced data analysis.\n",
    "\n",
    "## Final Thoughts:\n",
    "- This assessment is an opportunity for you to showcase your technical skills, problem-solving abilities, and your approach to learning and collaboration.\n",
    "- We appreciate the effort and time you put into this assessment and are excited to see your work.\n",
    "\n",
    "Best of luck, and we look forward to reviewing your submission!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF THE ASSESSMENT\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
